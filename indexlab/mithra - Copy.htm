<!doctype html>
<html lang="en">
<head>
	<!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="imgs/InDeXLab.gif"/>
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css" integrity="sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS" crossorigin="anonymous">
	
    <title>InDeX Lab. Mithra: Responsible Data Science and Algorithmic Fairness</title>
    <link rel="stylesheet" type="text/css" href="ppl.css" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <script type="text/javascript" src="js/myobjects.js"></script>
    <script type="text/javascript" src="js/MyFunctions.js"></script>
    <script type="text/javascript" src="js/myobjects.js"></script>
    <script type="text/javascript" src="js/indexstart.js"></script>
    <script type="text/javascript">
        function init() {
            header();
            //header2();
            fillContent("content/FairRanking.txt","FairR");
            fillContent("content/StableRanking.txt","StableR");
            fillContent("content/MithraRanking.txt","MithraR");
            fillContent("content/coverage.txt","coverage");
            fillContent("content/MithraCov.txt","mithracoverage");
            fillContent("content/nl1.txt","nl1");
            fillContent("content/nl2.txt","nl2");
        }
    </script>
</head>

<body onload='init()'>
    <div id="headerDiv"></div>
    <!-- Your code starts here -->
    <div class="container">
      <div class="jumbotron">
        <p style="width: 100%; text-align: center;"><img class="roundphoto" src="imgs/mithra_1.jpg"/></p>
        <h3 class="display-4">Mithra</h3>
        <p class="lead">Projects related to Responsible Data Science and Algorithmic Fairness</p>   
        <hr class="my-4">
        <p> Big data technologies have affected every corner of human life and society. These technologies have made our lives unimaginably more shared,  connected,  convenient,  and cost-effective. Using data-driven technologies gives us the ability to make wiser decisions, and can help make society safer, more equitable and just, and more prosperous.</p>
        <p>
            On the other hand, even if it looks promising, data-driven decision making can cause harm.
            Probably the main reason is that real-life social date is almost always ``biased''. No one can miss the extensive recent discussion about race in the context of policing and criminal justice.  But similar questions arise in many other domains as well.
            Take college admission for example. It has been shown that the GPA values has gender bias. That is due to grading policies that, for instance, may reduce grades for students with late homework, disruptive behavior, or inattention. As a result, using GPA as one of the features for generating the scores and ranking the students without considering the inherent bias in data can lead to gender bias.
            Evidence of bias has also been reported in recommendaton systems, advertisement, job interviewing, hiring, and promotion, among others.
        </p>
        <p style="text-align: center;"><img width="30%" src="imgs/dda.jpg"/></p>
        <p>
            In order to minimize societal harms of data-driven technologies, and to ensure that objectives such as fairness, equity, diversity, robustness, accountability, and transparency are satisfied, we aim to develop proper <i> algorithms, tools, strategies, and metrics</i>.
            In particular, we divide our effort in three categories:
            <dl>
                <dt>Data Prepration & Investigation:</dt>
                <dd>The focus of this category is on <i>bias in data</i> (colored in purple in the figure). 
                    Social data is almost always biased as it inherently reflects historical biases and stereotypes. Data collection and representation methods often introduce additional bias.
                    Using biased data without paying attention to societal impacts can create a <i>feedback loop</i>, and even increase discrimination in society.
                    Projects in this category aim to investigate the data used for building models and algorithms, (i) identify bias, and (iii) mitigate bias, and (iii) annotate data with information that show their fitness for use.
                </dd>
                <dt>Algorithm & Model Design:</dt>
                <dd>In particular, our focus is on score-based evaluation (colored in pink in the figure).
                    The scores are often derived by combining multiple criteria (aka features or attributes).
                    For instance, a lender may combine attributes such as payment history, salary, education, and age to develop a creditworthiness score for each customer.
                    The scores can be generated with different methods, linearly or using a complex function, and be used for different purposes.
                    In classification, scores are used to draw a decision boundary to specify, for example, if a  woman is at risk of developing invasive breast cancer over the next 5 years.
                    In ranking, the scores are used to sort the entities and, for example, select  the top-8 soccer teams for seeding pot 1 in the world cup tournament.
                    The scores are usually assigned either through (i) a process learned by machine learning models using some labeled training data, or (ii) using a weight vector or a procedure designed by human experts.
                    Our objective in these set of proects is to mitigate the bias in scoring algorithms to generate <i>fair</i> and <i>stable</i> outcomes. 
                </dd>
                <dt>Data Presentation & Output Investigation:</dt>
                <dd>
                    The projects in this category (i) provide tools for investigating and mitigating bias in the outcome of algorithms (ii) study how the data presentation can introduce bias.
                </dd>
              </dl>
            Below, you can find more details about each of the projects. You can also refer to the following publications for more details.
            <ul>
                <li> (Tutorial) Abolfazl  Asudeh,  HV  Jagadish. <a target="_blank" href="">Fairly Evaluating and Scoring Items in a Data Set</a>. <i>PVLDB</i>, 2020, VLDB Endowment.</li>
                <li> (Invited Paper) Abolfazl  Asudeh,  HV   Jagadish,  Julia  Stoyanovich. <a target="_blank" href="http://sites.computer.org/debull/A19sept/issue1.htm">Towards Responsible Data-driven Decision Making in Score-Based Systems</a>. <i>Data Engineering Bulletin</i>, Vol. 42(3), pages 76--87, 2019, Special Issue on Fairness, Diversity, and Transparency in Data Systems.</li>
            </ul>
        </p>
      </div>
      <div class="text-left">
        <ul class="list-group text-left" style="display:inline-block">
            <li class="list-group-item"><a href="#ranking">Responsible Ranking and Scoring</a>
                <ul>
                    <li><a href="#FairR">Fair Ranking Schemes</a></li>
                    <li><a href="#StableR">Stable Rankings</a></li>
                    <li><a href="#MithraR">MithraRanking (Demo)</a></li>
                </ul>
            </li>
            <li class="list-group-item"><a href="#BiasinData">Bias in Data</a>
                <ul>
                    <li><a href="#coverage">Coverage Assessment in a Dataset</a></li>
                    <li><a href="#mithracoverage">MithraCoverage (Demo)</a></li>
                </ul>            
            </li>
            <li class="list-group-item"><a href="#nl">Nutritional Labels</a>
                <ul>
                    <li><a href="#nl1">MithraLabel: Flexible Dataset Nutritional Labels (Demo)</a></li>
                    <li><a href="#nl2">Nutritional Labels for Rankings (Demo)</a></li>
                </ul> 
            </li>
        </ul>
       </div>

       <div>&nbsp;</div>
       <h3 id="ranking" class="alert alert-info" role="alert">Ranking and Scoring</h3>
       <div id="FairR"></div>
       <div>&nbsp;</div><div id="StableR"></div>
       <div>&nbsp;</div><div id="MithraR"></div>

       <div>&nbsp;</div>
       <h3 id="BiasinData" class="alert alert-info" role="alert">Bias in Data</h3>
       <div id="coverage"></div>
       <div>&nbsp;</div>
       <div id="mithracoverage"></div>

       <div>&nbsp;</div>
       <h3 id="nl" class="alert alert-info" role="alert">Nutritional Labels</h3>
       <div id="nl1"></div>
       <div>&nbsp;</div>
       <div id="nl2"></div>
    </div>
    <!-- Your code ends here -->
	<!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>
</body>
</html>