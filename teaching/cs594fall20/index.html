<html>
<head>
  <title>CS 594: Responsible Data Science and Algorithmic Fairness -- Fall 2020</title>
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css" integrity="sha384-GJzZqFGwb1QTTN6wy59ffF1BuGJpLSa9DkKMp0DgiMDm4iYMj70gZWKYbI706tWS" crossorigin="anonymous">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>
<body>
    <div class="container">
        <div class="jumbotron jumbotron-fluid text-center">
            <h1 class="display-4">CS 594: Responsible Data Science and Algorithmic Fairness</h1>
            <p class="lead">Fall 2020: T-Th 11:00 am -- 12:15 pm, Online (Zoom -- Link on Blackboard)</p>
            <hr class="my-4">
            <dl class="lead" style="text-align: left;padding-left: 10pt;">
                <dt>Instructor:</dt>
                    <dd>Abolfazl (Abol) Asudeh</dd>
                    <dd><i>Office:</i></td><td> SEO 1131 (<a href="mailto:asudeh@uic.edu">email</a>, <a href="http://www.cs.uic.edu/~asudeh">home page</a>)</dd>
                    <dd><i>Office Hours:</i></td><td> Th, 12:30am-2:30pm -- on Skype (a[dot]asudeh)</dd>
            </dl>
            <hr class="my-4">
            <div class="lead" style="text-align: left;padding-left: 10pt;">
                <a href="CS594_Syllabus_Fall20.pdf">Course Syllabus</a>
            </div>
        </div>
    </div>

    <div class="container">
        <h3 class="alert alert-info" role="alert"> Lecture Notes</h3>
        <table class="table">
        <thead>
          <tr>
            <th scope="col">Week</th>
            <th scope="col">Date</th>
            <th scope="col">Topic</th>
            <th scope="col">Slides</th>
            <th scope="col">Notes/Resources</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <th scope="row">1</th>
            <td>T. 8/25</td>
            <td>Course Introduction</td>
            <td><a href="0-CourseInto.pdf">Slides</a></td>
            <td></td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 8/27</td>
            <td>Harms of Data</td>
            <td><a href="1-HarmsofData.pdf">Slides</a></td>
            <td>
              Book: <a href="https://fairmlbook.org/" target="_blank">Fairness in Machine Learning</a>
              <br> <a href="l24.pdf">A Summary for Weapons of Math Destruction</a>
              <br> <a href="https://www.youtube.com/watch?v=zmdaCT086Gg">(Link to video) Ruha Benjamin: "Reimagining the Default Settings of Technology and Society"</a>
            </td>
          </tr>
          <tr>
            <th scope="row">2</th>
            <td>T. 8/29</td>
            <td>From Data to Action (Part 1)</td>
            <td></td>
            <td></td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>T. 9/3</td>
            <td colspan="2"></td>
            <td>Cancelled (Conflict with VLDB 2020 Presentation)<br><a href="https://www.cs.uic.edu/~indexlab/tutorial20.htm">Link to the Tutorial Slides and Videos</a></td>
          </tr>
          <tr>
            <th scope="row">3</th>
            <td>T. 9/8</td>
            <td>From Data to Action (Part 2)</td>
            <td><a href="2-FromDataToAction.pdf">Slides</a></td>
            <td></td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>T. 9/10</td>
            <td>On Fairness and its Definitions (Part 1)</td>
            <td><a href="3-FairnessDef-part1.pdf">Slides</a></td>
            <td><a href="https://www.youtube.com/watch?v=jIXIuYdnyyk&t=367s">(Link to video)  Arvind Narayanan: "Tutorial: 21 fairness definitions and their politics"</a></td>
          </tr>    
          <tr>
            <th scope="row">4</th>
            <td>T. 9/15</td>
            <td>On Fairness and its Definitions (Part 2)</td>
            <td><a href="3-FairnessDef-part2.pdf">Slides</a></td>
            <td><a href="https://www.youtube.com/watch?v=nWaM6XmQEmU">(Link to video) Judea Pearl: "The Foundations of Causal Inference" [The Book of WHY]</a></td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>T. 9/17</td>
            <td>On Fairness and its Definitions (Part 3)</td>
            <td><a href="3-FairnessDef-part3.pdf">Slides</a></td>
            <td><a href="https://www.youtube.com/watch?v=p5yY2MyTJXA">(Link to video) Jon Kleinberg: "Inherent Trade-Offs in Algorithmic Fairness"</a>
                <br><a href="http://videos.birs.ca/2018/18w5054/201801181717-Chouldechova.mp4">(Link to video) Alexandra Chouldechova: "Algorithmic bias: Practical and technical challenges"</a>
            </td>
          </tr>
          <tr>
            <th scope="row">5</th>
            <td>T. 9/22</td>
            <td>Beynod Fairness, related notions (Part 1)</td>
            <td><a href="4-BeyondFairness.pdf">Slides</a></td>
            <td><a href="https://www.youtube.com/watch?v=9J_KDjrhwUE">(Link to video) Jon Kleinberg: "Fairness, Rankings, and Behavioral Biases"</a>    
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>T. 9/24</td>
            <td>Beynod Fairness, related notions (Part 2)</td>
            <td></td>
            <td><a href="ProjectProposal.pdf">Project Proposal Instruction</a>    
            </td>
          </tr>
          <tr>
            <th scope="row">6</th>
            <td>T. 9/29</td>
            <td>Pre-process Interventions to Acheive Fairness (Part 1)</td>
            <td><a href="5-PreprocessInterventions.pdf">Slides</a></td>
            <td>    
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 10/1</td>
            <td>Pre-process Interventions to Acheive Fairness (Part 2)</td>
            <td></td>
            <td><span class="alert alert-danger" role="alert">Project Proposal Due (11:59pm)</span> </td>
          </tr>
          <tr>
            <th scope="row">7</th>
            <td>T. 10/6</td>
            <td>In-process Interventions to Acheive Fairness (Part 1 -- Classification)</td>
            <td><a href="6-InprocessInterventions-part1.pdf">Slides</a></td>
            <td>    
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 10/8</td>
            <td>In-process Interventions to Acheive Fairness (Part 2 -- Ranking)</td>
            <td><a href="6-InprocessInterventions-part2.pdf">Slides</a></td>
            <td>    
            </td>
          </tr>
          <tr>
            <th scope="row">8</th>
            <td>T. 10/13</td>
            <td>Paper Presentation (Shishir Adhikari)</td>
            <td><a href="CS594FairnessP1Shishir.pdf">Slides</a></td>
            <td>Salimi, Babak, et al. "Interventional fairness: Causal database repair for algorithmic fairness." in SIGMOD. 2019.
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 10/15</td>
            <td>Paper Presentation (Omid Memarrast)</td>
            <td><a href="CS594FairnessP2Omid.pdf">Slides</a></td>
            <td>Basu, Kinjal, et al. "A Framework for Fairness in Two-Sided Marketplaces." arXiv preprint arXiv:2006.12756 (2020).   
            </td>
          </tr>
          <tr>
            <th scope="row">9</th>
            <td>T. 10/20</td>
            <td>Paper Presentation (Mohammad Arvan)</td>
            <td><a href="marvan3_presentation.pdf">Slides</a></td>
            <td>Language (Technology) is Power: A Critical Survey of “Bias” in NLP 
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 10/22</td>
            <td>Paper Presentation (Shubham Singh)</td>
            <td><a href="FairTestSlides.pdf">Slides</a></td>
            <td>Tramer, Florian, et al. "FairTest: Discovering unwarranted associations in data-driven applications." 2017 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 2017.
            </td>
          </tr>
          <tr>
            <th scope="row">10</th>
            <td>T. 10/27</td>
            <td>Paper Presentation (Mina Valizadeh)</td>
            <td><a href="CS594-Presentation-NLP.pptx">Slides</a></td>
            <td>Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings (2016) by Tolga Bolukbasi et al.
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 10/29</td>
            <td>Paper Presentation (Nima Shahbazi)</td>
            <td><a href="CS594 Presentation-nima.pdf">Slides</a></td>
            <td>Feldman, Michael, et al. "Certifying and removing disparate impact." SIGKDD. 2015.<br>
              Adler, P., Falk, C., Friedler, S.A. et al. Auditing black-box models for indirect influence. Knowl Inf Syst 54, 95–122 (2018).
              <br> <a target="_blank" href="https://algofairness.github.io/fatconference-2018-auditing-tutorial/">(Tutorial) Auditing Black Box Models</a>
              <br> <a target="_blank" href="https://www.youtube.com/watch?v=rtDkl_0vLks">(Tutorial Video)</a>
              <br> <a target="_blank" href="https://github.com/algofairness/BlackBoxAuditing">Link to the github repository</a>
            </td>
          </tr> 
          <tr> 
            <th scope="row">11</th>
            <td>Th. 11/5</td>
            <td>Paper Presentation (Ishan Bhatnagar)</td>
            <td></td>
            <td>Kuppam, Satya, et al. "Fair decision making using privacy-protected data." arXiv preprint arXiv:1905.12744 (2019).
            </td>
          </tr>
          <tr>
            <th scope="row">12</th>
            <td>T. 11/10</td>
            <td>Paper Presentation (Sriparna Ghosh)</td>
            <td></td>
            <td>Palowitch, John, and Bryan Perozzi. "Monet: Debiasing graph embeddings via the metadata-orthogonal training unit." arXiv preprint arXiv:1909.11793 (2019).
              <br> Arduini, Mario, et al. "Adversarial Learning for Debiasing Knowledge Graph Embeddings." arXiv preprint arXiv:2006.16309 (2020).
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 11/12</td>
            <td>Paper Presentation (Ankit Aich)</td>
            <td></td>
            <td>How we talk about other people, group unfairness in natural language image description - AAAI - 2017
            </td>
          </tr>
          <tr>
            <th scope="row">13</th>
            <td>T. 11/17</td>
            <td>Paper Presentation (Teja Gollapudi)</td>
            <td></td>
            <td>“Why should I trust you? Explaining the predictions of any classifier”, Ribeiro, Singh, Guestrin (2016)
            </td>
          </tr>
          <tr>
            <th scope="row"></th>
            <td>Th. 11/19</td>
            <td></td>
            <td></td>
            <td></td>
          </tr>
        </tbody>
        </table>
    </div>
</body>
</html>
